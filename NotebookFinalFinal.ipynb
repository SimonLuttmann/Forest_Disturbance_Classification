{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36682add",
   "metadata": {},
   "source": [
    "### Case Study Groupe 10\n",
    "Arne Herlinghaus, Max LÃ¼tkemeyer, Thomas Mogos, Tim Strauss, Simon Luttmann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3110cfe0",
   "metadata": {},
   "source": [
    "# Final Model creation Workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c5b85a",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T22:11:40.041277Z",
     "start_time": "2025-05-20T22:11:40.038187Z"
    }
   },
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "585fdc70",
   "metadata": {},
   "source": [
    "#### Load original data"
   ]
  },
  {
   "cell_type": "code",
   "id": "dfe1c757215853f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T22:11:40.223065Z",
     "start_time": "2025-05-20T22:11:40.078376Z"
    }
   },
   "source": [
    "train_csv = \"data_6_channels_train.csv\"\n",
    "df = (pd.read_csv(train_csv)\n",
    "      .rename(columns={\"numerical_id\": \"forest_id\",\n",
    "                       \"class\": \"is_disturbance\",\n",
    "                       \"BLU\": \"blue\", \"GRN\": \"green\", \"RED\": \"red\",\n",
    "                       \"NIR\": \"near_infrared\",\n",
    "                       \"SW1\": \"shortwave_infrared_1\", \"SW2\": \"shortwave_infrared_2\"}))"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "06500cfd",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "id": "6680c708c5cf4a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T22:11:40.261687Z",
     "start_time": "2025-05-20T22:11:40.254028Z"
    }
   },
   "source": [
    "def engineer_features(group: pd.DataFrame, lags: int = 3) -> pd.DataFrame:\n",
    "    eps = 1e-6\n",
    "    g = group.copy()\n",
    "\n",
    "    # ---------- Base-Indices ----------------------------------------\n",
    "    g[\"NDVI\"] = (g.near_infrared - g.red) / (g.near_infrared + g.red + eps)\n",
    "    g[\"NDMI\"] = (g.near_infrared - g.shortwave_infrared_1) / (g.near_infrared + g.shortwave_infrared_1 + eps)\n",
    "    g[\"NDWI\"] = (g.green - g.near_infrared) / (g.green + g.near_infrared + eps)\n",
    "    g[\"NBR\"] = (g.near_infrared - g.shortwave_infrared_2) / (g.near_infrared + g.shortwave_infrared_2 + eps)\n",
    "    g[\"EVI\"] = 2.5 * (g.near_infrared - g.red) / (g.near_infrared + 6 * g.red - 7.5 * g.blue + 1 + eps)\n",
    "    g[\"NBR2\"] = (g.shortwave_infrared_1 - g.shortwave_infrared_2) / (\n",
    "                g.shortwave_infrared_1 + g.shortwave_infrared_2 + eps)\n",
    "    \n",
    "    # ---------- Dryness-Ratio -----------------------------------\n",
    "    g[\"SWIR_ratio\"] = g.shortwave_infrared_2 / (g.shortwave_infrared_1 + eps)\n",
    "\n",
    "    # ---------- Landsat-8 Tasseled-Cap (Baig 2014) -------------------\n",
    "    b2, b3, b4 = g.blue, g.green, g.red\n",
    "    b5, b6, b7 = g.near_infrared, g.shortwave_infrared_1, g.shortwave_infrared_2\n",
    "    g[\"TCB\"] = 0.3029 * b2 + 0.2786 * b3 + 0.4733 * b4 + 0.5599 * b5 + 0.5080 * b6 + 0.1872 * b7\n",
    "    g[\"TCG\"] = -0.2941 * b2 - 0.2430 * b3 - 0.5424 * b4 + 0.7276 * b5 + 0.0713 * b6 - 0.1608 * b7\n",
    "    g[\"TCW\"] = 0.1511 * b2 + 0.1973 * b3 + 0.3283 * b4 + 0.3407 * b5 - 0.7117 * b6 - 0.4559 * b7\n",
    "    g[\"TCT4\"] = -0.8239 * b2 + 0.0849 * b3 + 0.4396 * b4 - 0.0580 * b5 + 0.2013 * b6 - 0.2773 * b7\n",
    "    g[\"TCT5\"] = -0.3294 * b2 + 0.0557 * b3 + 0.1056 * b4 + 0.1855 * b5 - 0.4349 * b6 + 0.8085 * b7\n",
    "    g[\"TCT6\"] = 0.1079 * b2 - 0.9023 * b3 + 0.4119 * b4 + 0.0575 * b5 - 0.0259 * b6 + 0.0252 * b7\n",
    "\n",
    "    # --- Interaction-Features --------------------------------------\n",
    "    g[\"TCBxTCG\"] = g.TCB * g.TCG\n",
    "    g[\"TCBxTCW\"] = g.TCB * g.TCW\n",
    "    g[\"TCBxNBR\"] = g.TCB * g.NBR\n",
    "\n",
    "    # ---------- 3-Year-Median, Std, Anomalies (NDVI & NBR) ----------\n",
    "    for idx in (\"NDVI\", \"NBR\"):\n",
    "        g[f\"{idx}_med3\"] = g[idx].rolling(3, min_periods=2).median()\n",
    "        g[f\"{idx}_std3\"] = g[idx].rolling(3, min_periods=2).std()\n",
    "        g[f\"{idx}_anom\"] = (g[idx] - g[f\"{idx}_med3\"]) / (g[f\"{idx}_med3\"].abs() + eps)\n",
    "\n",
    "    # ---------- Lags & Deltas ---------------\n",
    "    base_cols = [\n",
    "        \"NDVI\", \"NDMI\", \"NDWI\", \"NBR\", \"EVI\", \"NBR2\", \"SWIR_ratio\",\n",
    "        \"TCB\", \"TCG\", \"TCW\", \"TCT4\", \"TCT5\", \"TCT6\",\n",
    "        \"TCBxTCG\", \"TCBxTCW\", \"TCBxNBR\",\n",
    "        \"blue\", \"green\", \"red\", \"near_infrared\", \"shortwave_infrared_1\", \"shortwave_infrared_2\"\n",
    "    ]\n",
    "\n",
    "    lag_features = []\n",
    "    for lag in range(1, lags + 1):\n",
    "        shifted = g[base_cols].shift(lag).rename(columns=lambda col: f\"l{lag}_{col}\")\n",
    "        deltas = (g[base_cols] - g[base_cols].shift(lag)).rename(columns=lambda col: f\"d{lag}_{col}\")\n",
    "        lag_features.extend([shifted, deltas])\n",
    "    g = pd.concat([g] + lag_features, axis=1)\n",
    "\n",
    "    # ---------- Time-Period-Features (assumption: forrest_disturbances occur in periods) ---------------\n",
    "    g[\"year_sin\"] = np.sin(2 * np.pi * g.year / 10)\n",
    "    g[\"year_cos\"] = np.cos(2 * np.pi * g.year / 10)\n",
    "\n",
    "    return g"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "db01be04c94dbece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T22:11:46.368048Z",
     "start_time": "2025-05-20T22:11:40.295067Z"
    }
   },
   "source": [
    "ft_file = \"all_data_all_features.csv\"\n",
    "\n",
    "if not Path(ft_file).exists():\n",
    "    feats = (df.groupby(\"forest_id\")\n",
    "             .apply(engineer_features)\n",
    "             .fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "             .reset_index(drop=True))\n",
    "    feats.to_csv(ft_file, index=False)\n",
    "else:\n",
    "    feats = pd.read_csv(ft_file)\n",
    "\n",
    "feature_cols = [c for c in feats.columns\n",
    "                if c not in (\"forest_id\", \"year\", \"is_disturbance\")]\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "ddbaf87d",
   "metadata": {},
   "source": [
    "#### Test|Validation 80|20 Split with Groups by forest_id"
   ]
  },
  {
   "cell_type": "code",
   "id": "f8bf66f5463793c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T22:11:46.857943Z",
     "start_time": "2025-05-20T22:11:46.410503Z"
    }
   },
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=42)\n",
    "tr_idx, va_idx = next(gss.split(feats, groups=feats[\"forest_id\"]))\n",
    "\n",
    "train_df, val_df = feats.iloc[tr_idx], feats.iloc[va_idx]\n",
    "X_train, y_train = train_df[feature_cols].values, train_df[\"is_disturbance\"].values\n",
    "X_val, y_val = val_df[feature_cols].values, val_df[\"is_disturbance\"].values\n",
    "print(f\"Train {len(train_df):,} | Val {len(val_df):,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 362,939 | Val 90,721\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "c835cdf6",
   "metadata": {},
   "source": " #### Hyperparameter-Tuning XGBoost Model via GridSearch and GroupKFold"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:35:49.927194Z",
     "start_time": "2025-05-20T22:56:29.572378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\":       [1250, 1500, 1750],\n",
    "    \"max_depth\":          [5, 6],\n",
    "    \"learning_rate\":      [0.02, 0.03, 0.05],\n",
    "    \"subsample\":          [0.6, 0.7],\n",
    "    \"colsample_bytree\":   [0.7, 0.8],\n",
    "    \"scale_pos_weight\":   [3],\n",
    "    \"gamma\":              [0.2, 0.25, 0.3],\n",
    "    \"min_child_weight\":   [2],\n",
    "}\n",
    "\n",
    "search_model = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"aucpr\",\n",
    "    eta=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.7,\n",
    "    min_child_weight=2,\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=60\n",
    ")\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=3)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=search_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=group_kfold,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False, groups=train_df['forest_id'])\n",
    "\n",
    "# Get the best parameters and the corresponding F1 score\n",
    "best_params = grid_search.best_params_\n",
    "best_f1_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best F1 Score: {best_f1_score}\")\n",
    "y_pred = grid_search.best_estimator_.predict(X_val)\n",
    "\n",
    "# Calculate F1 score and confusion matrix\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(f\"F1 Score on Validation Set: {f1}\")\n",
    "print(f\"Confusion Matrix on Validation Set:\\n{cm}\")"
   ],
   "id": "14f12c1ee56ac514",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim.strauss/Library/Python/3.9/lib/python/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 2, 'n_estimators': 1250, 'scale_pos_weight': 3, 'subsample': 0.6}\n",
      "Best F1 Score: 0.611825247337114\n",
      "F1 Score on Validation Set: 0.6013245033112583\n",
      "Confusion Matrix on Validation Set:\n",
      "[[90193   143]\n",
      " [  158   227]]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Threshold-Optimization",
   "id": "ed8fc436af524354"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:15:15.395395Z",
     "start_time": "2025-05-21T00:15:15.355013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "prec, rec, thr = precision_recall_curve(y_val, val_proba)\n",
    "f1_scores    = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "best_threshold = float(thr[np.argmax(f1_scores)])\n",
    "print(f\"best threshold (max F1 auf Val): {best_threshold:.3f}\")\n",
    "y_pred = (val_proba > best_threshold).astype(int)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print (f\"F1 Score on Validation Set: {f1:.4f}\")"
   ],
   "id": "bdb2da6c6c281544",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold (max F1 auf Val): 0.515\n",
      "F1 Score on Validation Set: 0.6016\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We chose the XGBoost model because it made the best predictions on our validation set compared to other Models like RandomForest, ExtraTrees, Logistic Regression and K-Nearest Neighbors.",
   "id": "fab2eea8"
  },
  {
   "cell_type": "markdown",
   "id": "7afdbbe4",
   "metadata": {},
   "source": "#### Prediction on test dataset"
  },
  {
   "cell_type": "code",
   "id": "bc90ed93ade748fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:15:56.682569Z",
     "start_time": "2025-05-21T00:15:24.159012Z"
    }
   },
   "source": [
    "test_csv = \"data_6_channels_test_pub.csv\"\n",
    "out_npy = \"data_6_channels_test_pub_with_predictions.npy\"\n",
    "\n",
    "orig_test = pd.read_csv(test_csv)\n",
    "\n",
    "test_tmp = (\n",
    "    orig_test\n",
    "    .rename(columns={\n",
    "        \"numerical_id\": \"forest_id\",\n",
    "        \"BLU\": \"blue\",\n",
    "        \"GRN\": \"green\",\n",
    "        \"RED\": \"red\",\n",
    "        \"NIR\": \"near_infrared\",\n",
    "        \"SW1\": \"shortwave_infrared_1\",\n",
    "        \"SW2\": \"shortwave_infrared_2\",\n",
    "    })\n",
    ")\n",
    "\n",
    "test_feat = (\n",
    "    test_tmp\n",
    "    .groupby(\"forest_id\", group_keys=False)\n",
    "    .apply(engineer_features)\n",
    "    .fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "X_test    = test_feat[feature_cols].values\n",
    "test_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "test_pred = (test_prob >= best_threshold).astype(int)\n",
    "\n",
    "pred_df = (\n",
    "    test_feat[[\"forest_id\", \"year\"]]\n",
    "    .assign(is_disturbance=pred)\n",
    "    .rename(columns={\"forest_id\": \"numerical_id\"})\n",
    ")\n",
    "\n",
    "merged = orig_test.merge(\n",
    "    pred_df,\n",
    "    on=[\"numerical_id\", \"year\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "col_order = [\n",
    "    \"is_disturbance\"\n",
    "]\n",
    "merged = merged[col_order]\n",
    "\n",
    "np.save(out_npy, merged[\"is_disturbance\"].to_numpy())\n",
    "print(\n",
    "    f\"â '{out_npy}' geschrieben â 0={(merged.is_disturbance == 0).sum():,} | \"\n",
    "    f\"1={(merged.is_disturbance == 1).sum():,}\"\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/s6j5yq4s12j6wvms4084h50h0000gn/T/ipykernel_93774/2062413000.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_tmp\n",
      "/var/folders/9l/s6j5yq4s12j6wvms4084h50h0000gn/T/ipykernel_93774/2062413000.py:20: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_tmp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â 'data_6_channels_test_pub_with_predictions.npy' geschrieben â 0=112,980 | 1=444\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:16:27.016698Z",
     "start_time": "2025-05-21T00:16:27.012357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pred_loaded = np.load(\"data_6_channels_test_pub_with_predictions.npy\")\n",
    "\n",
    "if pred_loaded.shape == (113424,): print('Shape is correct')\n",
    "else: print('Shape is incorrect')"
   ],
   "id": "743ffd343d0e9e31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is correct\n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
